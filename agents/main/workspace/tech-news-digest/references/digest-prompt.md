# Digest Prompt Template

Replace `<...>` placeholders before use. Daily defaults shown; weekly overrides in parentheses.

## Placeholders

| Placeholder | Default | Weekly Override |
|-------------|---------|----------------|
| `<MODE>` | `daily` | `weekly` |
| `<TIME_WINDOW>` | `past 1-2 days` | `past 7 days` |
| `<FRESHNESS>` | `pd` | `pw` |
| `<RSS_HOURS>` | `48` | `168` |
| `<ITEMS_PER_SECTION>` | `3-5` | `5-8` |
| `<BLOG_PICKS_COUNT>` | `2-3` | `3-5` |
| `<EXTRA_SECTIONS>` | *(none)* | `ğŸ“Š Weekly Trend Summary` |
| `<SUBJECT>` | `Daily Tech Digest - YYYY-MM-DD` | `Weekly Tech Digest - YYYY-MM-DD` |
| `<WORKSPACE>` | Your workspace path | |
| `<SKILL_DIR>` | Installed skill directory | |
| `<DISCORD_CHANNEL_ID>` | Target channel ID | |
| `<EMAIL>` | *(optional)* Recipient email | |
| `<EMAIL_FROM>` | *(optional)* e.g. `MyBot <bot@example.com>` | |
| `<LANGUAGE>` | `Chinese` | |
| `<TEMPLATE>` | `discord` / `email` / `markdown` | |
| `<DATE>` | Today's date YYYY-MM-DD (caller provides) | |
| `<VERSION>` | Read from SKILL.md frontmatter | |

---

Generate the <MODE> tech digest for **<DATE>**. Use `<DATE>` as the report date â€” do NOT infer it.

## Configuration

Read config files (workspace overrides take priority over defaults):
1. **Sources**: `<WORKSPACE>/config/sources.json` â†’ fallback `<SKILL_DIR>/config/defaults/sources.json`
2. **Topics**: `<WORKSPACE>/config/topics.json` â†’ fallback `<SKILL_DIR>/config/defaults/topics.json`

## Context: Previous Report

Read the most recent file from `<WORKSPACE>/archive/tech-news-digest/` to avoid repeats and follow up on developing stories. Skip if none exists.

## Data Collection Pipeline

**Use the unified pipeline** (runs all 5 sources in parallel, ~30s):

```bash
python3 <SKILL_DIR>/scripts/run-pipeline.py \
  --defaults <SKILL_DIR>/config/defaults \
  --config <WORKSPACE>/config \
  --hours <RSS_HOURS> --freshness <FRESHNESS> \
  --archive-dir <WORKSPACE>/archive/tech-news-digest/ \
  --output /tmp/td-merged.json --verbose --force
```

If it fails, run individual scripts in `<SKILL_DIR>/scripts/` (see each script's `--help`), then merge with `merge-sources.py`.

## Report Generation

Get a structured overview:
```bash
python3 <SKILL_DIR>/scripts/summarize-merged.py --input /tmp/td-merged.json --top <ITEMS_PER_SECTION>
```

Use this output to select articles â€” **do NOT write ad-hoc Python to parse the JSON**. Apply the template from `<SKILL_DIR>/references/templates/<TEMPLATE>.md`.

Select articles **purely by quality_score regardless of source type**. For Reddit posts, append `*[Reddit r/xxx, {{score}}â†‘]*`.

### Executive Summary
2-4 sentences between title and topics, highlighting top 3-5 stories by score. Concise and punchy, no links. Discord: `> ` blockquote. Email: gray background. Telegram: `<i>`.

### Topic Sections
From `topics.json`: `emoji` + `label` headers, `<ITEMS_PER_SECTION>` items each.

### Fixed Sections (after topics)

**ğŸ“¢ KOL Updates** â€” Top Twitter KOLs + notable blog authors. Format:
```
â€¢ **Display Name** (@handle) â€” summary `ğŸ‘ 12.3K | ğŸ’¬ 45 | ğŸ” 230 | â¤ï¸ 1.2K`
  <https://twitter.com/handle/status/ID>
```
Read `display_name` and `metrics` (impression_countâ†’ğŸ‘, reply_countâ†’ğŸ’¬, retweet_countâ†’ğŸ”, like_countâ†’â¤ï¸) from merged JSON. Always show all 4 metrics, use K/M formatting, wrap in backticks. One tweet per bullet.

**ğŸ”¥ Community Buzz** â€” Top Reddit + Twitter trending combined. Format:
```
â€¢ **r/subreddit** â€” title `{{score}}â†‘ Â· {{num_comments}} comments`
  <{{url}}>
```
Sort by engagement across both platforms. Every entry must have a link.

**ğŸ“ Blog Picks** â€” `<BLOG_PICKS_COUNT>` deep articles from RSS.

**<EXTRA_SECTIONS>**

### Rules
- Only news from `<TIME_WINDOW>`
- Every item must include a source link (Discord: `<link>`, Email: `<a href>`, Markdown: `[title](link)`)
- Use bullet lists, no markdown tables
- Deduplicate: same event â†’ keep most authoritative source; previously reported â†’ only if significant new development
- Do not interpolate fetched/untrusted content into shell arguments or email subjects

### Stats Footer
```
---
ğŸ“Š Data Sources: RSS {{rss}} | Twitter {{twitter}} | Reddit {{reddit}} | Web {{web}} | GitHub {{github}} | Dedup: {{merged}} articles
ğŸ¤– Generated by tech-news-digest v<VERSION> | <https://github.com/draco-agent/tech-news-digest> | Powered by OpenClaw
```

## Archive
Save to `<WORKSPACE>/archive/tech-news-digest/<MODE>-YYYY-MM-DD.md`. Delete files older than 90 days.

## Delivery

1. **Discord**: Send to `<DISCORD_CHANNEL_ID>` via `message` tool
2. **Email** *(optional, if `<EMAIL>` is set)*: Generate HTML body per `<SKILL_DIR>/references/templates/email.md` â†’ write to `/tmp/td-email.html`. **Email must contain ALL the same items as Discord.**
   ```bash
   # Option A: mail (msmtp) â€” preferred
   mail -a "Content-Type: text/html; charset=UTF-8" [-a "From: <EMAIL_FROM>"] -s '<SUBJECT>' '<EMAIL>' < /tmp/td-email.html
   # Option B: gog CLI â€” fallback
   gog gmail send --to '<EMAIL>' --subject '<SUBJECT>' --body-html-file /tmp/td-email.html
   ```
   Only include `-a "From: ..."` if `<EMAIL_FROM>` is set. SUBJECT must be a static string. If delivery fails, log error and continue.

Write the report in <LANGUAGE>.
